{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.apply(lambda x:sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing values with mean/mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[''].fillna(mode(train['']).mode[0],inplace = True)\n",
    "train[''].fillna(np.math.ceil(np.mean(train[''])),inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pivot table similar to Pivot table in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(train,index=[\"Outlet_Size\"],values=[\"Item_Outlet_Sales\"],\n",
    "                  columns=[\"Item_Fat_Content\"],aggfunc=[np.mean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting by Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train[['Item_Identifier','Item_Fat_Content','Item_Outlet_Sales']]\n",
    "\n",
    "#(or)\n",
    "\n",
    "remove_cols = ['Item_Fat_Content','Item_Outlet_Sales']\n",
    "train.drop(remove_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting by Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train[['Item_Identifier','Item_Fat_Content','Item_Outlet_Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the required rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the last n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[-5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the last n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:-5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the required Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train[['Item_Identifier','Item_Fat_Content','Item_Outlet_Sales','Item_Visibility','Outlet_Location_Type']]\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:,0:2]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the first n cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:,:3]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the first n cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:,3:]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the last n cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:,-3:]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the last n cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train1.iloc[:,:-3]\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of Categorical and Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns = []\n",
    "cat_columns = []\n",
    "\n",
    "for i in train.columns:\n",
    "    if train[i].dtype == 'float':\n",
    "        cont_columns.append(i)\n",
    "    elif train[i].dtype == 'object':\n",
    "        cat_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_columns)\n",
    "print(cont_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Variables from a Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = train['Item_Identifier']\n",
    "#Drop unnecessary columns\n",
    "train.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing variables from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns.pop(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Outlet_Sales'] = np.log1p(train['Item_Outlet_Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair wise Visualizations with target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[cont_columns], vars=['Item_Weight','Item_Visibility','Item_MRP','Item_Outlet_Sales'], kind = 'scatter',diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = train.plot.scatter(x='Item_MRP',\n",
    "                        y='Item_Outlet_Sales',\n",
    "                        c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Item_Outlet_Sales'\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(np.log1p(train.Item_Outlet_Sales))\n",
    "plt.title(\"Histogram of Target Variable- %s\" %target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix for continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix = train[cont_columns].corr().abs()\n",
    "\n",
    "plt.subplots(figsize=(13, 9))\n",
    "sns.heatmap(correlationMatrix,annot=True)\n",
    "\n",
    "# Mask unimportant features\n",
    "sns.heatmap(correlationMatrix, mask=correlationMatrix < 1, cbar=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Variables Distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "sns.boxplot(x=\"Item_Weight\", data =train,orient='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness in Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "skewness_list = []\n",
    "for cn in train[cont_columns].columns:\n",
    "    skewness_list.append(stats.skew(train[cn]))\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(skewness_list, 'bo-')\n",
    "plt.xlabel(\"continous features\")\n",
    "plt.ylabel(\"skewness\")\n",
    "plt.title(\"plotting skewness of the continous features\")\n",
    "plt.xticks(range(15), range(1,15,1))\n",
    "plt.plot([(0.25) for i in range(0,14)], 'r--')\n",
    "plt.text(6, .1, 'threshold = 0.25')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Skewed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cont_columns = []\n",
    "for i, cn in enumerate(cont_columns):\n",
    "    if skewness_list[i] >= 0.25:\n",
    "        skewed_cont_columns.append(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "plt.figure(figsize=(15,25))\n",
    "gs = gridspec.GridSpec(6, 2)\n",
    "for i, cn in enumerate(skewed_cont_columns):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    sns.distplot(train[cn], bins=50)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('hist plot of feature: ' + str(cn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Plot of all Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Item_Fat_Content','Outlet_Size','Outlet_Location_Type']\n",
    "\n",
    "#Plot count plot for all attributes in a 29x4 grid\n",
    "n_cols = 3\n",
    "n_rows = 1\n",
    "for i in range(n_rows):\n",
    "    fg,ax = plt.subplots(nrows=1,ncols=n_cols,sharey=True,figsize=(12, 8))\n",
    "    for j in range(n_cols):\n",
    "        sns.countplot(x=cols[i*n_cols+j], data=train, ax=ax[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Count, CountUniq, Cumsum, Mean at certain levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count (Eg: Count of Oulet Size)\n",
    "group_cols = ['Outlet_Size']\n",
    "agg_name = 'Outlet_Size_Count'\n",
    "gp = train[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "print(gp)\n",
    "#train = train.merge(gp, on=group_cols, how='left')\n",
    "\n",
    "## Count Unique (Eg: Unique count of Location Type at Outlet Size level)\n",
    "group_cols = ['Outlet_Size']\n",
    "counted = 'Outlet_Location_Type'\n",
    "gp = train[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "#print(gp)\n",
    "train = train.merge(gp, on=group_cols, how='left')\n",
    "\n",
    "## Cummulative Count (Eg: Cum count of Outlet Size at Item Fat Content Level level)\n",
    "group_cols = ['Item_Fat_Content']\n",
    "counted = 'Outlet_Size'\n",
    "gp = train[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "#print(gp)\n",
    "train = train.merge(gp, on=group_cols, how='left')\n",
    "\n",
    "## Mean (Eg: Mean of Sales at Item_Fat_Content Level)\n",
    "group_cols = ['Item_Fat_Content']\n",
    "counted = 'Item_Outlet_Sales'\n",
    "agg_name = 'Item_Fat_Content_mean_Sales'\n",
    "gp = train[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "#print(gp)\n",
    "train = train.merge(gp, on=group_cols, how='left')\n",
    "\n",
    "## Mean (Eg: Mean of Sales at Item_Fat_Content Level)\n",
    "group_cols = ['Item_Fat_Content']\n",
    "counted = 'Item_Outlet_Sales'\n",
    "agg_name = 'Item_Fat_Content_variance_Sales'\n",
    "gp = train[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "#print(gp)\n",
    "train = train.merge(gp, on=group_cols, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train\n",
    "train1['lag1'] = train1['Item_Outlet_Sales'].shift()\n",
    "\n",
    "## Lag at a certain Level\n",
    "train1['Lag_Fat_Content_Level'] = train1.groupby('Item_Fat_Content')['Item_Outlet_Sales'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting of Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train1.sort_index(by=['Item_Fat_Content', 'Item_Type'], ascending=[True, True])\n",
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Item_Fat_Content','Outlet_Size'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding of Categorical Featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train1 = train\n",
    "le = LabelEncoder().fit(train1['Item_Fat_Content'])\n",
    "train1['Item_Fat_Content'] = le.transform(train1['Item_Fat_Content'])\n",
    "print (train1.head())\n",
    "\n",
    "## Reverse Tranform\n",
    "train1['Item_Fat_Content']= (le.inverse_transform(train1['Item_Fat_Content']))\n",
    "print (train1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "for i in cat_columns:\n",
    "    train1[i] = le_sex.fit_transform(train1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X=train1.values\n",
    "\n",
    "#Scaling the values\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=131)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var= pca.explained_variance_ratio_\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X = train.loc[:, train.columns != 'Item_Outlet_Sales']\n",
    "y = train['Item_Outlet_Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# The mean Absolute error\n",
    "print(\"Mean Absolute error: %.2f\"\n",
    "      % np.mean(abs(regr.predict(X_val) - Y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(regr.predict(X_val), Y_val,color='black')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "res = sm.Logit(y_train,X_train)\n",
    "\n",
    "## Print the Summary\n",
    "res.summary()\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Regression\n",
    "from sklearn import tree\n",
    "model = tree.DecisionTreeRegressor() \n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Output\n",
    "predicted= model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,y_train)\n",
    "dvalid = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x,train_y)\n",
    "params = {\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"max_depth\":6,\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"eta\": 0.05,\n",
    "    \"silent\": 1,\n",
    "    'colsample':0.9,\n",
    "    'subsample':0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "xgb = xgb.train(params, dtrain,500, evals=watchlist,\n",
    "                early_stopping_rounds=10, verbose_eval=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
